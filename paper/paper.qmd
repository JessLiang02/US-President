---
title: "Polling Insights for the 2024 U.S. Election: Predicting Support for Donald Trump"
subtitle: "Timing, Geography, and Poll Quality Affect Donald Trump's Support Levels"
author: 
  - Jing Liang
  - Jierui Zhan
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder]."
date: today
date-format: long
abstract: "This study examines factors affecting Donald Trump’s support levels before the 2024 U.S. presidential election, including poll end date, state, pollster, and poll quality. We find significant variations in support based on geographic location and poll quality, with higher-quality polls reporting lower support for Trump. These findings highlight the need to critically evaluate polling methodologies for accurate public opinion interpretations. Our work enhances understanding of voter sentiment dynamics, supporting informed political discourse amid scrutiny of polling accuracy."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(here)
library(arrow)
library(modelsummary)
```

# Introduction

In recent years, polling has become a critical tool for measuring public opinion and predicting political outcomes, particularly in U.S. presidential elections. As public reliance on polling data has grown, so has the need for scrutiny around its reliability and accuracy. Factors such as timing, geographic variation, pollster methodology, and poll quality can significantly affect reported levels of candidate support. For example, the timing of a poll relative to key campaign events or the methods used by different pollsters can cause variations in the support reported for candidates. These inconsistencies raise important questions about how polling differences, particularly across states and polling organizations, impact public opinion forecasts. In the context of the 2024 U.S. election, a clear understanding of these dynamics is crucial for accurate poll interpretation, particularly regarding Donald Trump’s percentage support.

This paper aims to fill a gap in the literature by systematically analyzing how polling variables such as end date, state, pollster, and poll score influence Trump's support. The estimand in this analysis is the percentage support for Donald Trump as reported in polls. While previous studies have examined isolated factors like poll timing or specific pollsters, few have investigated how these variables interact. Using a linear regression model, we assess the contributions of each variable, exploring how factors such as time, geographic region, and poll quality influence polling results. Additionally, we account for potential non-linearities and omitted variables, such as demographic and economic factors, that may further explain variations in Trump’s support.

Our findings identify several key influences on polling outcomes. State-level differences in support are significant, with some states consistently showing higher or lower levels of support for Trump. Poll score also plays a critical role, with higher-quality polls typically reporting lower support, indicating that less rigorous polls may overestimate Trump’s backing. Additionally, the analysis reveals pollster-specific biases, where certain organizations systematically report higher or lower support, necessitating careful consideration of pollster effects. Diagnostic tests show potential violations of key model assumptions, such as heteroscedasticity and non-normality, suggesting that more sophisticated models may be needed to better capture these relationships. These results are crucial for improving the accuracy of election forecasts and ensuring more reliable interpretations of polling data.

The structure of this paper is organized as follows. @sec-data introduces the data sources and the key variables utilized in our analysis, offering a comprehensive overview of the dataset and how the variables were selected. @sec-model outlines the modeling strategy, including the linear regression framework, along with its underlying assumptions and the rationale for the inclusion of specific predictors like state, pollster, and poll score. @sec-results presents the model results, emphasizing the significant factors driving Trump’s percentage support and analyzing any diagnostic issues such as heteroscedasticity and residual normality. @sec-discussion delves into the broader implications of our findings, discussing their relevance to polling accuracy, potential biases, and offering suggestions for future research to enhance predictive modeling in political contexts.

# Data {#sec-data}

## Overview

For this analysis, we employed the R programming language [@citeR] to examine polling data on public sentiment before the election. Our dataset, sourced from FiveThirtyEight [@fivethirtyeight2024], offers a detailed snapshot of evolving public opinion. We explored key influences on percentage support, including the timing of the polls, pollster characteristics, and geographic differences.

Several `R` packages were instrumental in performing data manipulation, modeling, and visualization. `tidyverse` was the backbone for organizing and analyzing the data efficiently, allowing seamless integration of multiple tasks [@thereferencecanbewhatever]. `here` streamlined file path handling, ensuring smooth data access across systems [@citehere]. We relied on `janitor` for robust data cleaning, helping identify and fix potential inconsistencies [@citejanitor], and `lubridate` facilitated the manipulation of time-related variables [@citelubridate]. Additionally, `arrow` provided fast and memory-efficient access to large datasets, a critical factor for managing extensive polling data [@citearrow]. Finally, `testthat` facilitates efficient unit testing on the simulated and the analysis datasets. The structure of the codebase and workflow adhered to the best practices outlined in @tellingstories.

## Measurement
	
Accurately measuring Donald Trump’s support is crucial for our analysis, as it converts the complex and often conflicting opinions of individuals into reliable numerical data. We begin by standardizing survey design and question phrasing across different polling organizations to minimize measurement bias. By ensuring that questions are consistently formulated—such as using uniform language like "Do you support Donald Trump for President?"—we reduce variability introduced by differing methodologies. Representative sampling techniques, including random digit dialing and stratified sampling, are employed to capture a diverse and accurate snapshot of voter sentiment. These methods ensure that our sample mirrors the demographic and geographic composition of the electorate, thereby enhancing the validity of our support measurements.

The primary outcome variable, Trump’s percentage support, is derived through meticulous data aggregation and weighting processes. Poll results from sources like FiveThirtyEight [@fivethirtyeight2024] are combined into a comprehensive dataset, where each poll is weighted based on factors such as sample size, sampling method, and poll quality. This weighting standardizes the data, mitigating the impact of outlier polls or those with limited geographic coverage. Additionally, we conduct validation and reliability checks by comparing our measurements against historical data and actual election outcomes to identify and correct potential sources of error, such as non-response bias or misreporting. This rigorous approach ensures that our percentage support figures accurately reflect public opinion over time and across different states.

Equally important are the precise measurements of our predictor variables: poll end date, state, pollster, and poll quality. Poll end date is recorded as the date when data collection concluded, allowing us to track temporal trends in support. The state variable identifies the geographical location of each poll, enabling regional analysis of support levels. Pollster denotes the organization conducting the poll, accounting for methodological differences that may influence results. Poll quality, assessed through a comprehensive poll score, reflects the reliability and methodological rigor of each poll based on sample size, sampling techniques, and question phrasing. By ensuring the integrity of both outcome and predictor variables through standardization, calibration, and transparency, we establish a robust foundation for analyzing the factors that shape voter sentiment, ultimately providing meaningful insights into the electoral landscape leading up to the 2024 U.S. presidential election.

## Outcome variable

### The percentage support for Trump in the poll

The percentage support for Trump in polls represents the portion of respondents who favor Donald Trump in a given survey. This measure is crucial in gauging his popularity, especially in the context of upcoming elections. Expressed as a percentage, it ranges from 0 to 100, with higher values indicating greater support. The percentage of support can vary across different polls depending on factors such as sample size, region, and methodology. A strong polling result with higher percentages suggests robust backing, while lower percentages indicate weaker favorability among the surveyed population.

@fig-pct shows Trump's percentage support across polls, mostly clustered between 40% and 50%. There's a peak around 45%, with a slight right skew indicating a few polls showing higher support, up to 55%. Very few polls show support below 30% or above 50%, suggesting moderate and stable backing with minimal outliers. This distribution reflects consistent mid-range support for Trump across the sampled polls.

```{r}
#| label: fig-pct
#| fig-cap:  Trump's polling support, predominantly ranging from 40% to 50% with a peak around 45%. The distribution shows a slight right skew and minimal outliers below 30% or above 50%, indicating consistent mid-range backing.
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_parquet(here::here("data/02-analysis_data/analysis_data.parquet"))
ggplot(analysis_data, aes(x = pct)) +
  geom_histogram(binwidth = 1, fill = "springgreen2", color = "black") +
  labs(x = "Percentage support",
       y = "Frequency") +
  theme_bw()
```

## Predictor variables

### End date

The end date marks the final day of data collection for a poll, signaling the close of the survey period. It provides critical context by showing when the poll reflects public opinion, as sentiments can evolve rapidly due to factors like news cycles, political events, or campaign strategies. The earliest end date is `r min(analysis_data$end_date)` and the latest end date is `r max(analysis_data$end_date)`.

### State

The state variable indicates where the poll was conducted, either in a specific U.S. state (e.g., Arizona or California) or across the nation ("National"). State polls focus on regional voter preferences, while national polls provide an overall view of public sentiment across the country. This distinction helps in analyzing both local and nationwide trends.

@fig-state shows the number of polls conducted, with national polls leading by a wide margin, surpassing 250. Wisconsin, Pennsylvania, and Arizona have the highest number of state-specific polls, each below 60. Other key states like Michigan, Georgia, and Texas follow, while states like Missouri and Colorado have the fewest. The focus on national and battleground states highlights their electoral importance.

```{r}
#| label: fig-state
#| fig-cap: Distributino of polls by states - over 250 national polls, with Wisconsin, Pennsylvania, and Arizona leading state-specific polls (each under 60). Fewer polls in Missouri and Colorado highlight the focus on national and battleground states.
#| echo: false
#| warning: false
#| message: false

state_count <- analysis_data %>%
  count(state) %>%
  arrange(desc(n))
ggplot(state_count, aes(x = fct_reorder(state, n, .desc = F), y = n)) +
  geom_bar(stat = "identity", fill = "springgreen2", color = "black") +
  labs(x = "State",
       y = "Number of Polls") + coord_flip() + 
  theme_bw() 
```

### Poll score

The poll score is a rating that measures the reliability and quality of a poll based on various criteria, including the pollster’s history, the clarity of their methodology, and the sample's representativeness. Higher scores indicate greater credibility, suggesting the poll follows rigorous methods and provides an accurate reflection of public opinion. In contrast, lower scores may reveal flaws such as bias, insufficient sample sizes, or poor transparency, making the results less dependable for drawing conclusions.

@fig-pollscore displays the distribution of poll scores, with two distinct peaks. Most polls cluster around scores of -1.5 and -1.1, indicating that the majority of polls have similar ratings. There is a small number of polls with scores around -1.3, suggesting less frequent variation in the middle of the range.

```{r}
#| label: fig-pollscore
#| fig-cap: The distribution of poll scores with two main peaks at -1.5 and -1.1, and a smaller peak around -1.3. This indicates that most polls have similar ratings, with minimal variation in the middle range.
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = pollscore)) +
  geom_histogram(binwidth = 0.05, fill = "springgreen2", color = "black") +
  labs(x = "Poll score",
       y = "Frequency") +
  theme_bw()
```

### Pollster

The pollster are known as the organization responsible for conducting the poll, such as Emerson, YouGov, or Quinnipiac. These organizations collect data to gauge public opinion on various topics, including political preferences. Each pollster employs its own methodologies, sampling, and geographic coverage, which can lead to variations in results and influence the overall reliability of the poll.

@fig-pollster illustrates the number of polls conducted by various polling organizations. YouGov leads with over 200 polls, followed closely by Siena/NYT, which has just under 200. Other pollsters, such as Marquette Law School, have significantly fewer polls, and the remaining organizations conducted only a handful of surveys.

```{r}
#| label: fig-pollster
#| fig-cap: The number of polls by organization. YouGov leads with over 200 polls, followed by Siena/NYT with just under 200. Other pollsters, such as Marquette Law School, conducted significantly fewer surveys.
#| echo: false
#| warning: false
#| message: false
pollster_count <- analysis_data %>%
  count(pollster) %>%
  arrange(desc(n))
ggplot(pollster_count, aes(x = fct_reorder(pollster, n, .desc = F), y = n)) +
  geom_bar(stat = "identity", fill = "springgreen2", color = "black") +
  labs(x = "Pollster",
       y = "Number of Polls") + coord_flip() + 
  theme_bw() 
```

## Variable associations

@fig-pctpollscore displays the distribution of percentage support for various pollsters, with the poll score on the vertical axis. Each box represents the interquartile range of the percentage support, while the whiskers extend to the minimum and maximum values, with outliers indicated by dots. Pollsters like YouGov and Siena/NYT show more variability in support, while Marquette Law School and ABC/Washington Post have tighter ranges. Some pollsters, such as YouGov Blue, have more consistent results with smaller interquartile ranges, indicating more stable percentage support.

```{r}
#| label: fig-pctpollscore
#| fig-cap: Depicts the percentage support distributions for various pollsters. YouGov and Siena/NYT exhibit greater variability, while Marquette Law School, ABC/Washington Post, and YouGov Blue show tighter, more consistent ranges.
#| echo: false
#| warning: false
#| message: false

ggplot(analysis_data, aes(x = reorder(pollster, -pct), y = pct)) +
  geom_boxplot(fill = "springgreen2") +
  labs(x = "Poll score",
       y = "Percentage support") +
  theme_bw()+ coord_flip() 
```

@fig-pctstate displays the distribution of percentage support across different states. Colorado, Virginia, and Nebraska CD-2 show the highest median support, while states like Missouri and Montana have the lowest median support levels. The variability in the percentage support is noticeable, with several states, such as Michigan and Wisconsin, displaying wider interquartile ranges, indicating greater variation in support. Outliers in states like Arizona and National suggest some polls reported either higher or lower support compared to the majority.

```{r}
#| label: fig-pctstate
#| fig-cap: Trump’s support distribution by state. Colorado, Virginia, and Nebraska CD-2 have the highest median support, while Missouri and Montana show the lowest. Michigan and Wisconsin exhibit greater variability, and Arizona and National polls contain outliers indicating higher or lower support levels.
#| echo: false
#| warning: false
#| message: false
 
ggplot(analysis_data, aes(x = reorder(state, -pct), y = pct)) +
  geom_boxplot(fill = "springgreen2") +
  labs(x = "State",
       y = "Percentage support") +
  theme_bw() +
  coord_flip()  
```

# Model {#sec-model}

Our aim is to quantify the relationship between key variables, such as the end date of the poll, the state, the poll score, and the pollster, and the percentage support for Trump. We employ a linear regression model to investigate how each of these factors influences support levels. Our linear regression model includes the end date, pollster, state, and poll score as predictors, allowing us to quantify their individual impact. By estimating the coefficients, we can assess the direction and strength of their effects, providing insights into which variables play the most significant role in shaping public opinion.  More comprehensive details on the model's specification, underlying assumptions, and diagnostic checks are provided in [Appendix @sec-model-spec] and [Appendix -@sec-model-diag]. For a full description of the validation procedures used, please refer to [Appendix -@sec-model-valid].

The modeling choices align with the structure of the data. We treat the end date as a continuous variable to capture any linear trends over time. Pollster and state are treated as categorical variables to reflect inherent group differences without assuming any specific order. Poll score remains continuous to preserve its detail and capture the nuanced impact of poll quality on support levels. These decisions ensure that essential characteristics of the data are preserved, allowing for a more accurate and informative analysis.

## Model set-up

### Model 1: Percentage support as a function of end date

The first model investigates how the end date of a poll impacts the percentage of support for Trump. Mathematically, it is represented as:

$$
\begin{aligned}
y_i & =\beta_0+\beta_1 x_{1 i}+\epsilon_i \\
\epsilon_i & \sim \operatorname{Normal}\left(0, \sigma^2\right)
\end{aligned}
$$

Where:

- $y_i$ denotes the percentage support for Trump in poll $i$
- $x_{1 i}$ is the end date of poll $i$
- $\beta_0$ represents the intercept, which is the baseline level of support
- $\beta_1$ captures the effect of the end date on percentage support
- $\epsilon_i$ is the error term, assumed to follow a normal distribution with a mean of 0 and variance $\sigma^2$

### Model 2: Percentage support as a function of end date, state, poll score, and pollster

In the second model, we extend the analysis by including additional variables: the state in which the poll was conducted, the poll score, and the pollster. The equation is as follows:

$$
\begin{aligned}
& y_i=\beta_0+\beta_1  x_{1 i}+\beta_2  x_{2 i}+\beta_3  x_{3 i}+\beta_4  x_{4 i}+\epsilon_i \\
& \epsilon_i \sim \operatorname{Normal}\left(0, \sigma^2\right)
\end{aligned}
$$


Where:

- $y_i$ represents the percentage support for Trump in poll $i$,
- $x_{1 i}$ is the end date of the poll
- $x_{2 i}$ corresponds to the state where the poll was conducted
- $x_{3 i}$ is the poll score, indicating the quality of the poll
- $x_{4 i}$ represents the pollster who conducted the poll
- $\beta_0$ is the intercept
- $\beta_1, \beta_2, \beta_3, \beta_4$ are the coefficients corresponding to each predictor variable, measuring their individual effects
- $\epsilon_i$ is the error term, which follows a norma ${ }^1$ - istribution with mean 0 and variance $\sigma^2$

We run the models in R [@citeR].

### Modeling justification

The first model examines how the end date of a poll influences Trump’s percentage support, based on the idea that public opinion shifts over time due to external events or campaign developments. By treating the end date as a continuous variable, the model captures trends in support, where polls conducted closer to the election are expected to reflect more accurate voter preferences. The linear regression approach provides a simple way to quantify this relationship.

The second model expands by incorporating state, poll score, and pollster as additional predictors. These variables are key factors influencing polling outcomes, as state-level differences, poll quality, and methodologies of various pollsters can all affect the results. Including these predictors allows the model to control for geographic and methodological variations, offering a clearer picture of the factors driving Trump’s support. The use of linear regression ensures that the model remains interpretable while accounting for these important influences.

While linear regression models were selected for their simplicity and interpretability, several alternative approaches were considered to potentially capture more complex relationships within the polling data. Hierarchical (Multilevel) Models were evaluated for their ability to account for nested data structures, such as polls within states or pollsters. However, the added complexity was deemed unnecessary given the study's focus on general trends and the limited sample sizes within each subgroup. Machine Learning Algorithms, including random forests and gradient boosting machines, were also considered for their capacity to model non-linear relationships and interactions without explicit specification. Despite their superior predictive accuracy, these models were excluded due to their reduced interpretability, which is crucial for understanding the specific factors influencing Trump’s support.

Additionally, Time Series Models like ARIMA and Exponential Smoothing were explored to handle temporal dependencies in the data. However, the cross-sectional nature of the polling dataset and the incorporation of poll end dates as continuous predictors made these models less suitable. Logistic Regression was considered but ultimately rejected because the outcome variable of interest—Trump’s percentage support—is continuous rather than binary. Lastly, Structural Equation Modeling (SEM) was evaluated for its ability to analyze complex relationships between variables, but the requirement for substantial data and strong theoretical foundations led to its exclusion in favor of the more straightforward linear regression approach. These decisions ensure that the chosen models effectively balance complexity, interpretability, and the study’s primary objectives of elucidating clear and actionable insights into voter sentiment dynamics.

# Results {#sec-results}

Our results are summarized in @tbl-modelresults. 

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

model1 <- 
  readRDS(file = here::here("models/model_date.rds"))
model2 <- 
   readRDS(file = here::here("models/model_date_state_pollscore_pollster.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Model results"
#| warning: false

modelsummary(models = list("Model 1" = model1, "Model 2" = model2))
```

In Model 1, the intercept is estimated at -131.653 , meaning that when the end date is at zero (far back in time), the predicted percentage support for Trump would be negative, though this has no real-world interpretation due to the range of actual dates. The coefficient for end date is positive (0.009), indicating that as time progresses (later end dates), Trump's percentage support slightly increases by 0.009 percentage points per day. This is a statistically significant result given the low standard error (0.001). The model explains $13.2 \%$ of the variation in support ( $R^2=0.132$ ), which is relatively modest, and has a root mean square error (RMSE) of 3.96, meaning there is some error in the predictions.

Model 2 expands on the predictors, including state, poll score, and pollster. The intercept decreases to -223.206, with the coefficient for end date still positive but slightly smaller (0.008), showing a similar upward trend in support over time. Many state-level coefficients show how different states' support for Trump compares to the baseline category (Colorado). For instance, Florida has a positive and statistically significant coefficient (5.903), suggesting higher support for Trump compared to Colorado, while Nebraska CD-2 has a negative coefficient (-5.475), indicating lower support.

The poll score has a negative coefficient (-92.960), meaning higher poll quality (or score) tends to show lower support for Trump. Among pollsters, Siena/NYT has a notably negative coefficient (-35.982), indicating that this pollster tends to report significantly lower Trump support compared to the baseline.

Model 2 improves overall fit, explaining $35 \%$ of the variation in support ( $R^2=0.350$ ) and reducing the RMSE to 3.43, indicating better predictive accuracy. The AIC and BIC values also decrease (AIC = 2605.4, BIC = 2709.8), suggesting that Model 2 is a better fit compared to Model 1.

Overall, the expanded Model 2 captures more variation in support, with state, poll score, and pollster contributing significantly to the predictive power.

# Discussion {#sec-discussion}

## Influence of State-Level Variability on Support 

Model 2 reveals significant variability in Trump’s percentage support across different states. For instance, states like Florida and Missouri show a positive and statistically significant increase in support compared to the baseline (Colorado), while Nebraska CD-2 and Virginia exhibit lower support. This demonstrates the importance of geographic factors in understanding voter preferences, as state-specific dynamics heavily influence the overall level of support. Campaign strategies might need to be tailored for individual states, especially swing states or regions showing significant divergence in support.

## Impact of Poll Score on Reported Support

The poll score coefficient in Model 2 is negative, suggesting that polls with higher methodological rigor or better quality report lower support for Trump. This is an important finding, as it indicates that lower-quality polls might overstate Trump’s support, potentially leading to biased or skewed interpretations of his popularity. This result emphasizes the need to critically evaluate poll quality when analyzing and aggregating polling data to avoid misleading conclusions.

## Improvement in Model Performance with Additional Predictors 

The improvement in model fit ($R^2$ increasing from 0.132 in Model 1 to 0.350 in Model 2) and the reduction in RMSE (from 3.96 to 3.43) highlights the importance of including multiple factors in the analysis. Adding state, poll score, and pollster as predictors significantly enhances the model's ability to explain the variability in Trump’s percentage support. This suggests that relying solely on temporal trends (as in Model 1) may miss key contextual factors, such as the influence of geographic and methodological differences, in explaining public opinion.

## Overall Influence of Factors on Percentage Support

The inclusion of multiple factors in Model 2—such as state, poll score, and pollster—demonstrates that Trump’s percentage support is influenced by a combination of geographic, methodological, and temporal factors. The model highlights that no single variable fully explains the variation in support, but rather, a combination of these factors work together to shape public opinion. The coefficients for state-level variables suggest that regional differences play a significant role, while the poll score and pollster coefficients indicate that the methodology and quality of the polls themselves also have a measurable impact. This underscores the importance of considering multiple dimensions when analyzing polling data, as relying solely on one factor (such as time) may overlook key influences such as regional trends or poll quality. 

## Weaknesses and next steps

Model 2, while an improvement over Model 1, may still suffer from omitted variable bias as key demographic factors like age, education, and economic conditions are not included. These variables likely influence Trump's support across different states and their absence could limit the model's ability to fully explain variation. Additionally, the residual plot and the Normal Q-Q plot suggest potential heteroscedasticity and deviations from normality (@fig-diag-1; @fig-diag-2), indicating the model struggles with capturing non-linear dynamics or outliers, particularly during significant shifts in public opinion or extreme polling outcomes. The limited pollster-specific effects also fail to account for interactions between pollsters and factors like state or poll quality, which could lead to oversimplified interpretations of polling data.

To address these issues, future models should consider including demographic and economic variables to improve accuracy and capture a more comprehensive picture of Trump's support. Additionally, exploring non-linear relationships using polynomial terms or splines could help better capture the complexity of public opinion changes over time. It would also be valuable to investigate interaction effects between pollster, state, and poll score to understand how these factors jointly influence results. Finally, addressing the heteroscedasticity and potential non-normality identified in the residual plots, through transformations or the use of robust standard errors, will improve the model's reliability and interpretation.

\newpage

\appendix

# Appendix {-}

## Model specification {#sec-model-spec}

The model specification assumes a linear relationship between predictors (such as end date, state, poll score, and pollster) and Trump’s percentage support. It also assumes homoscedasticity, meaning the variance of errors is constant across all fitted values, and that errors are independently and normally distributed. The model also treats pollster and state as categorical variables, assuming no interaction effects between them and other factors. These assumptions provide a straightforward, interpretable model.

## Model diagnostics {#sec-model-diag}

@fig-diag-1 shows the relationship between the fitted values (predicted Trump support) and the residuals (errors). Ideally, the residuals should be randomly distributed around zero without any clear pattern or clusters, which would indicate a linear good model fit and that the independent errors assumption is satisfied. However, this plot shows some visible structure and a potential funnel shape, suggesting possible heteroscedasticity, meaning that the variance of the residuals changes with the fitted values. This may indicate that the model’s assumptions of constant variance are violated, warranting further investigation into model improvements or the need for transformation of variables.

@fig-diag-2 compares the residuals to a theoretical normal distribution. If the residuals are normally distributed, the points should closely follow the red line. In this case, most of the points lie along the line, suggesting that the residuals are approximately normal. However, there is some deviation at the tails, particularly at the lower end, where the residuals fall below the line. This indicates potential non-normality in the distribution of residuals, particularly in the extremes, which may suggest that the model struggles to fit extreme values as accurately.

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-diag
#| fig-cap: "Checking assumptions of the linear regression model (model 2)"
#| fig-subcap: ["Residuals vs. fitted values", "Normal Q-Q plot of residuals"]
#| layout-ncol: 2

# Residuals vs Fitted Plot
ggplot(data.frame(Fitted = model2$fitted.values, Residuals = resid(model2)), aes(x = Fitted, y = Residuals)) +
  geom_point(color = "darkblue", alpha = 0.3) +  
  geom_hline(yintercept = 0, color = "red", linetype = "dashed", size = 1) +  
  labs(x = "Fitted values", y = "Residuals") +  
  theme_bw()

# Q-Q Plot of Residuals
ggplot(data.frame(Residuals = resid(model2)), aes(sample = Residuals)) +
  stat_qq(color = "darkgreen", alpha = 0.6) + 
  stat_qq_line(color = "red", size = 1) + 
  labs(x = "Theoretical quantiles", y = "Sample quantiles") + 
  theme_bw()
```

## Model validation {#sec-model-valid}

Model validation via Root Mean Square Error (RMSE) is an important aspect of assessing the accuracy and predictive power of regression models. RMSE provides a measure of how well the model's predicted values align with the actual observed values, specifically focusing on the magnitude of prediction errors.

The RMSE tells us how far off the model's predictions are from the actual values, in the same units as the dependent variable (percentage support). In this context, an RMSE of 3.43 means that, on average, Model 2's predictions deviate from the true percentage support by approximately 3.43 percentage points. This is an improvement over Model 1, where the average deviation is about 3.96 percentage points. While both RMSE values are relatively low, the reduction in RMSE from Model 1 to Model 2 suggests that including additional predictors (such as state and poll score) meaningfully enhances the model's precision. This improvement is particularly important for making more informed predictions, as Model 2 captures more variability in the data.

\newpage

## Deep Dive into YouGov's Methodology

### Introduction

YouGov has established itself as a leading polling organization, renowned for its systematic and transparent approach to gathering public opinion data [@yougov_panel_methodology]. By leveraging innovative sampling techniques, robust data quality measures, and advanced analytical methods, YouGov consistently delivers reliable insights into public sentiment. This section provides an in-depth exploration of YouGov's methodology, detailing the processes involved in transforming individual opinions into aggregate results, the strategies employed to ensure representativeness, and the measures taken to maintain data integrity and participant privacy.

### Sampling Strategy

**Online Panel Composition**

Central to YouGov's methodology is its extensive online panel, designed to represent the U.S. adult population accurately. This panel is constructed through a diverse recruitment strategy that includes digital advertising campaigns, partnerships with various online platforms, and outreach initiatives targeting specific demographic groups. By utilizing multiple channels for recruitment, YouGov ensures a wide-ranging demographic representation encompassing varying age groups, races, ethnicities, education levels, and political affiliations. This diversity is crucial for capturing the multifaceted nature of public opinion and ensuring that the panel mirrors the broader population.

**Recruitment and Retention**

Recruiting and retaining panelists is a critical aspect of maintaining a representative sample. YouGov employs incentive-based strategies to encourage participation, such as offering points that can be redeemed for rewards or donations to charitable causes. Additionally, YouGov prioritizes user-friendly survey interfaces and timely feedback to enhance the participant experience, thereby reducing attrition rates. Regular engagement through personalized communications and periodic check-ins helps sustain panelist interest and commitment, ensuring a stable and active panel over time.

**Nonprobability Sampling Approach**

One significant aspect of YouGov's methodology is its nonprobability sampling approach. Unlike probability sampling, which relies on random selection to achieve representativeness, nonprobability sampling allows for rapid and cost-effective data collection by recruiting participants who opt into the panel. While this method offers logistical advantages, it raises concerns about potential self-selection bias, where individuals who choose to join the panel may differ systematically from those who do not. To address this, YouGov implements rigorous demographic matching and weighting processes to align the panel's composition with national demographic benchmarks, thereby mitigating biases and enhancing representativeness.

### Data Collection Methods

**Questionnaire Design**

When conducting surveys, YouGov prioritizes quality through meticulous questionnaire design. Surveys typically incorporate a variety of question types, including multiple-choice, Likert scales, and open-ended formats, allowing for the capture of nuanced opinions and comprehensive data analysis. The design process emphasizes clarity and neutrality, ensuring that questions are free from leading language that could skew responses. Additionally, YouGov frequently employs randomization techniques in question order to minimize response bias and order effects, thereby enhancing the reliability of the collected data.

**Pre-testing and Pilot Studies**

To ensure the effectiveness of questionnaire designs, YouGov conducts extensive pre-testing and pilot studies. These preliminary tests involve administering draft surveys to a subset of the panel to identify potential issues with question wording, survey flow, and technical functionality. Feedback from these tests is used to refine the survey instruments, ensuring that they accurately capture the intended information and are easily understood by respondents. This iterative process helps prevent ambiguities and reduces the likelihood of measurement errors, thereby enhancing the overall quality of the data collected.

### Data Quality and Integrity

**Weighting and Calibration**

Once data collection is complete, YouGov employs a thorough weighting process to adjust the results so that they accurately reflect the broader population. Weighting involves assigning different levels of importance to respondents based on demographic characteristics such as age, gender, race, education, and political affiliation. By comparing the sample's demographics to established benchmarks from sources like the U.S. Census Bureau, YouGov can adjust the influence of individual responses to align more closely with actual population distributions. This calibration process is critical in addressing any residual biases resulting from the nonprobability sampling approach and ensuring that the final reported results provide an accurate portrayal of public opinion.

**Response Quality Assessments**

To maintain high data quality, YouGov employs a multifaceted strategy involving continuous monitoring, testing, and refinement of survey responses. This includes verifying panelists' identities through email and IP address checks to prevent fraudulent participation. Additionally, response quality assessments evaluate the consistency and reliability of participant answers, identifying patterns indicative of inattentive or dishonest responses. Respondents who consistently fail these quality checks may be flagged for further review or removed from the panel, thereby preserving the integrity of the dataset.

### Mitigating Self-Selection Bias

**Demographic Matching**

Addressing self-selection bias is paramount in nonprobability sampling. YouGov mitigates this by employing demographic matching techniques that adjust the panel's composition to mirror national demographic profiles. This involves weighting responses based on demographic segments that are overrepresented or underrepresented in the panel. By doing so, YouGov ensures that the aggregated data reflects the diversity of the general population, thereby enhancing the validity of the polling results.

**Continuous Panel Monitoring**

YouGov continually monitors the characteristics of its panelists to maintain a balanced representation. This involves tracking participation rates across different demographic groups and adjusting recruitment strategies as needed to fill gaps. For instance, if younger age groups are underrepresented, targeted recruitment efforts may be initiated to bolster participation from these segments. This dynamic approach helps maintain the panel's representativeness over time, ensuring that the polling data remains robust and reliable.

### Analytical Techniques

**Multilevel Regression with Post-Stratification (MRP)**

A key methodological approach employed by YouGov is Multilevel Regression with Post-Stratification (MRP). MRP combines multilevel modeling with post-stratification techniques to estimate voting behavior and other public opinion metrics across different demographics and geographic regions. By leveraging data collected from their panelists, YouGov can predict voting patterns with a higher degree of accuracy, accounting for the complex interplay of demographic factors and regional variations. This sophisticated modeling technique allows for granular insights into public sentiment, enabling more precise forecasting of election outcomes.

**Advanced Statistical Modeling**

In addition to MRP, YouGov utilizes a range of advanced statistical models to analyze polling data. These include time-series analyses to track changes in public opinion over time, factor analyses to identify underlying dimensions of voter sentiment, and cluster analyses to segment respondents based on shared characteristics. These analytical techniques facilitate a deeper understanding of the drivers of public opinion and enhance the predictive power of YouGov's polling models.

### Ensuring Transparency and Reproducibility

**Methodological Transparency**

YouGov is committed to maintaining transparency in its polling methodologies. Detailed documentation of survey designs, sampling strategies, weighting procedures, and analytical techniques is made available to researchers and the public. This openness allows for independent verification of results and fosters trust in YouGov's polling processes. By providing comprehensive methodological insights, YouGov enables stakeholders to critically evaluate the reliability and validity of the polling data.

**Reproducible Research Practices**

To further promote reproducibility, YouGov adheres to best practices in data management and analysis. This includes maintaining detailed logs of data collection processes, preserving raw and processed datasets, and utilizing standardized coding practices in data analysis scripts. By ensuring that research processes are transparent and reproducible, YouGov facilitates collaborative research and enables other analysts to replicate and build upon their findings.

### Participant Privacy and Data Security

**Data Protection Measures**

Protecting the privacy of panelists is a cornerstone of YouGov's methodology. Participants retain control over their personal data, with options to opt out of data sharing and to request modifications or deletions of their information. YouGov employs robust data protection measures, including encryption of sensitive information, secure storage protocols, and strict access controls to prevent unauthorized access to personal data. These measures comply with relevant data protection regulations and industry standards, ensuring that panelists' privacy rights are upheld.

**Ethical Considerations**

YouGov prioritizes ethical considerations in all aspects of its polling operations. This includes obtaining informed consent from participants, ensuring voluntary participation, and providing clear information about how their data will be used. Additionally, YouGov adheres to ethical guidelines for research involving human subjects, promoting fairness, transparency, and respect for individual rights. By upholding these ethical standards, YouGov fosters trust among panelists and the broader public, enhancing the credibility of its polling results.

### Addressing Methodological Challenges

**Balancing Speed and Accuracy**

One of the inherent challenges in polling is balancing the need for rapid data collection with the necessity of maintaining accuracy and reliability. YouGov addresses this by leveraging its extensive online panel, which allows for swift deployment of surveys without compromising on sample representativeness. The use of automated data collection and processing systems further enhances efficiency, enabling YouGov to provide timely insights while upholding methodological rigor.

**Handling Non-Response Bias**

Non-response bias occurs when certain groups are less likely to participate in surveys, potentially skewing the results. YouGov mitigates this by implementing strategic panel management techniques that target underrepresented groups and encourage participation through tailored incentives. Additionally, the weighting process adjusts for non-response patterns by aligning the sample demographics with national benchmarks, thereby reducing the impact of non-response bias on the final results.

**Adapting to Technological Changes**

As digital landscapes evolve, so do the methods for collecting and analyzing polling data. YouGov stays at the forefront of technological advancements by continuously updating its survey platforms, incorporating new data collection tools, and adopting innovative analytical techniques. This adaptability ensures that YouGov remains capable of capturing accurate and relevant public opinion data in an increasingly digital and interconnected world.

### Comparative Analysis with Other Polling Organizations

**Methodological Differentiation**

Compared to other polling organizations, YouGov's nonprobability sampling approach and extensive online panel distinguish it in the polling landscape. While traditional pollsters often rely on probability sampling methods such as random digit dialing, YouGov's approach allows for greater flexibility and speed in data collection. This methodological differentiation enables YouGov to conduct frequent and large-scale surveys, providing timely insights into public opinion trends.

**Performance and Accuracy**

YouGov has demonstrated a track record of accurate polling in various elections and referendums. Its use of advanced statistical models like MRP enhances the precision of its predictions, particularly in estimating support levels across different demographics and regions. By continuously refining its methodologies and incorporating feedback from past polling performance, YouGov maintains a high standard of accuracy and reliability in its results.

**Strengths and Limitations**

YouGov's strengths lie in its innovative sampling strategies, robust data quality measures, and commitment to transparency. These factors contribute to the organization's ability to produce reliable and actionable public opinion data. However, inherent limitations associated with nonprobability sampling, such as potential self-selection bias, remain challenges that YouGov actively addresses through demographic weighting and continuous panel monitoring. Understanding these strengths and limitations is essential for interpreting YouGov's polling results within the broader context of public opinion research.

### Future Directions and Innovations

**Enhancing Sampling Techniques**

Looking ahead, YouGov aims to further enhance its sampling techniques by integrating behavioral and psychographic data to achieve even greater representativeness. Incorporating data on respondents' online behaviors, media consumption habits, and social interactions can provide deeper insights into the factors shaping public opinion. This holistic approach to sampling will enable YouGov to capture a more comprehensive picture of voter sentiment and improve the granularity of its polling data.

**Expanding Analytical Capabilities**

YouGov is investing in expanding its analytical capabilities by adopting machine learning and artificial intelligence (AI) technologies. These advancements will facilitate the identification of complex patterns and relationships within the polling data, enhancing the predictive power of YouGov's models. By leveraging AI-driven analytics, YouGov can offer more sophisticated insights into voter behavior and public opinion dynamics.

**Strengthening Participant Engagement**

To sustain and grow its online panel, YouGov is focused on strengthening participant engagement through personalized interactions and enhanced user experiences. Implementing gamification elements, providing real-time feedback on survey participation, and offering more flexible incentive structures are strategies aimed at increasing panelist motivation and reducing attrition rates. These efforts will ensure a vibrant and active panel capable of delivering high-quality polling data.

### Conclusion

YouGov’s methodology combines innovative sampling techniques, rigorous data quality measures, and a strong commitment to transparency and participant privacy. The organization’s nonprobability sampling approach, while presenting challenges related to self-selection bias, is effectively mitigated through comprehensive demographic weighting and continuous panel monitoring. Advanced analytical methods, such as Multilevel Regression with Post-Stratification (MRP), enhance the accuracy and interpretability of polling results, providing valuable insights into public opinion dynamics. Additionally, YouGov's dedication to ethical practices and data security fosters trust among participants and stakeholders alike. By continuously adapting to technological advancements and refining its methodologies, YouGov remains at the forefront of public opinion research, delivering reliable and actionable data that informs political discourse and decision-making processes in the lead-up to elections.

\newpage

## Idealized Methodology for Forecasting the U.S. Presidential Election

**Budget Overview**

With a budget of $100,000, this project will focus on a comprehensive methodology designed to gather, analyze, and interpret public opinion data regarding the U.S. presidential election. The aim is to construct a robust survey framework that allows for precise forecasting of voter behavior and sentiment. The investment will primarily be allocated toward panel recruitment, survey development, data collection, and statistical modeling. This financial backing will ensure high-quality data acquisition and analysis, contributing significantly to the accuracy of the forecasts.

**Sampling Approach**

Target Population:

The survey will target all eligible voters in the United States, specifically adults aged 18 and older. This broad demographic will enable a comprehensive understanding of voter preferences and sentiments across different segments of the population. Within this overarching target, the sampling will be stratified to ensure representation from key demographics, including age, gender, race, income level, education, and geographic location. Stratified random sampling is crucial, as it helps to capture the diversity of the U.S. electorate, allowing for a more nuanced analysis of how different factors influence support for presidential candidates.

Sampling Technique:

A probability sampling method will be employed, focusing on stratified random sampling. This approach allows for a representative selection of respondents based on predetermined demographic criteria. By ensuring that various segments of the population are adequately represented, we can minimize selection bias and enhance the reliability of the results. The sample size will aim for approximately 2,000 respondents, which strikes a balance between statistical reliability and resource efficiency, targeting a margin of error of 2% at a 95% confidence level. This sample size is sufficient to capture variations in voter support across different demographic and regional groups.

**Respondent Recruitment**

Panel Development:

To assemble the sample, respondents will be recruited through a multi-channel strategy. This includes targeted online advertising, partnerships with civic organizations, and outreach via social media platforms. The objective is to attract a diverse array of participants, encompassing various socioeconomic and demographic backgrounds. This method not only increases the pool of potential respondents but also enhances the inclusivity of the sample, allowing for a more accurate reflection of the electorate.

Incentives for Participation:

Respondents will receive monetary incentives or gift cards for completing the survey. These incentives are crucial for encouraging participation, especially among demographics that might be less inclined to engage in online surveys. Additionally, the recruitment process will emphasize the importance of each individual's contribution to understanding public sentiment, which can motivate participation based on a desire to influence research outcomes.

Online Survey Platform:

Surveys will be conducted using Google Forms, allowing respondents to complete them on their smartphones, tablets, or computers at their convenience. The design will incorporate a mix of question types, including multiple-choice, Likert scales, and open-ended questions. This variety will facilitate a comprehensive understanding of voter attitudes and preferences, making it easier to analyze the data effectively.

**Data Validation**

Quality Control Measures:

Ensuring data integrity will be paramount. YouGov will implement a robust quality control system that includes various verification techniques. Each respondent's identity will be confirmed through email verification and IP address checks to prevent duplicate or fraudulent responses. Additionally, response time will be monitored to ensure participants are thoughtfully engaging with the survey rather than rushing through it.

Demographic Weighting:

After data collection, statistical weighting will be applied to adjust for any demographic imbalances in the sample compared to the national population, using U.S. Census data as a benchmark. This weighting process is critical for enhancing the accuracy of the findings, ensuring that the results reflect the broader electorate's opinions.

**Poll Aggregation and Modeling**

Aggregation Techniques:

The survey results will be aggregated with existing polling data from reputable sources, such as FiveThirtyEight and Gallup. This will involve a weighted polling model that combines results from various polls to produce a more reliable overall estimate. By pooling data from multiple sources, we can mitigate the impact of any single poll's biases, resulting in a more robust analysis of voter sentiment.

Statistical Modeling:

A multilevel regression with post-stratification (MRP) approach will be used to estimate candidate support across different demographics and geographic segments. This technique has been effective in previous elections, allowing us to account for complex interactions between variables [@kiewiet2018predicting]. By training the model with data from our survey and integrating it with aggregated polling data, we can refine our forecasts and provide a more nuanced view of voter behavior leading up to the election.

**Reporting and Transparency**

Results Dissemination:

The findings from this research will be compiled into a comprehensive report detailing the methodology, demographic breakdown, key insights, and margin of error. This report will be made publicly available to ensure transparency and build trust in the results. Engaging with civic organizations and stakeholders will be essential to communicate findings and foster discussions about voter engagement and turnout strategies.

In summary, this idealized methodology for forecasting the U.S. presidential election combines rigorous sampling techniques, effective respondent recruitment, and thorough data validation. By utilizing a well-structured online survey platform and employing advanced statistical modeling, the project aims to deliver accurate insights into voter sentiment, ultimately contributing to a better understanding of the electoral landscape in the lead-up to the election. This comprehensive approach ensures that the data collected will provide valuable information for both political analysts and decision-makers.

**Survey Implementation**

The survey has been developed using Google Forms, allowing for easy access and completion across various devices. This platform facilitates user-friendly interaction, enabling respondents to provide their insights conveniently. The survey can be accessed through the following link: https://forms.gle/4VjHGLDEbmwiy9ex6

\newpage

# References


